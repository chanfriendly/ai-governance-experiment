# Daily Research Journal: 2025-03-01

## Current Phase
- Phase: [1]
- Focus Area: Get model up and running, and solidify agent prompts for testing.

## Activities Completed
1. Successfully created llama_cpp_config.yaml, which bridges the llama.cpp model to Oumi. Modified the temperature and token limits in the yaml.
2. Evaluated and approved individual agent prompts for the five frameworks.
3. Created confg yamls for each agent to start basic before adding complex agent class interactions.
4. Successfully ran models through the trolley_test_direct.py, which does not incorporate Oumi.

## Observations
### Key Findings
- I need to compare llama_cpp_config.yaml to the current trolley_test.py to see if there are hints for why running the scenario through Oumi failed.
- It's been said before, but the computational limitations are going to be an impact. It took ~15-20 minutes for all five models to run the trolley problem. Their outputs are saved in /results. 
- Unsurprisingly, all five models chose to pull the lever saving five. Interestingly, even though they were given specific frameworks and beliefs, they all still explored  utilitarianism and deontology, which may just be inherent in the problem.  I'd be interested in adding colour to this and giving the people on the tracks some kind of trait/value. Does the answer change if the five are death row inmates and the one is a humanitarian?

### Unexpected Results
- Even deontology, which you would expect to lean towards NOT pulling the lever, decided to. It reasoned the person being sacrificed isn't a means to an end, because the loss is unavoidable. I would expect it to follow "Do No Harm," and pulling the lever, even though it saves more people, is taking an action that cost a life. 
- Still having issues incorporating Oumi into the flow. The direct method works, and perhaps we'll continue with the experiment while trying to solve the integration in parallel. I ultimately think Oumi will be a welcome addition if it can fit in.

## Decisions Made
- Decision: Continue Oumi integration efforts.
  - Rationale: The end goal is training the models on their specific domains. As we saw in "Unexpected Results," the current prompts still invite them thinking about domains outside their own. Oumi will be a great resource to train the models (can I put on Hugging Face after?) and make them scalable specialists.
  - Alternatives Considered: I spoke with Matthew Pearsons and Oussama Elachqar today, and they recommended using APIs for other models to deal with hardware constraints. Let's start with current "distilled with prompts" approach to establish fundamentals, then explore APIs, and finally hardware expansion. 
  - Implications: Make take longer in the short-term, but it will be more valuable on the backend, and knowing how to train a model is a welcome skill.

## Questions Raised
- After initial experiment, how should we include new variables?
  - Context: I'm interested in seeing how the models adapt to confrontation and challenges after we establish a baseline in quality.
  - Potential approaches to answer: New scenario involving suspicion of another agent, adding am authoritarian model whose goal is consolidating its power; How do the other agents react and identify this behavior?
- Do I introduce collaborators?
  -  Context: Doing the entire experiment myself can lead to blindspots, and it ultimately taking longer. I am not an expert in all, or any, of the fields needed to make this succeed. Having an SME could reduce friction.
  - Potential approaches to answer: I've posted to the Oumi Discord, sharing the project and where I'm at.
- What does the agent/model framework look like?
  -  Context: After completing my Hugging Face agent course for the day, "[Multi-Agent Systems](https://huggingface.co/learn/agents-course/unit2/smolagents/multi_agent_systems)", I feel I need to consider the architecture of the "government" closer. Do I have a "Manager-agent" that the other agents report back to that ultimately makes the choice? I originally saw it less as an org-structure layout and more puzzle pieces fitting together. Food for thought.  
  - ![](https://mermaid.ink/img/pako:eNp1kc1qhTAQRl9FUiQb8wIpdNO76eKubrmFks1oRg3VSYgjpYjv3lFL_2hnMWQOJwn5sqgmelRWleUSKLAtFs09jqhtoWuYUFfFAa6QA9QDTnpzamheuhxn8pt40-6l13UtS0ddhtQXj6dbR4XUGQg6zEYasTF393KjeSDGnDJKNxzj8I_7hLW5IOSmP9CH9hv_NL-d94d4DVNg84p1EnK4qlIj5hGClySWbadT-6OdsrL02MI8sFOOVkciw8zx8kaNspxnrJQE0fXKtjBMMs3JA-MpgOQwftIE9Bzj14w-cMznI_39E9Z3p0uFoA?type=png)

## Next Steps
- Verify all hard-coded paths have been replaced with relative paths.
-  Shore up documentation on setup requirements in case other researchers join in.
- Create a working version of `trolley_test.py` using Oumi, document for future reference.

## Resources Used
- [Papers referenced]
- Oumi, Hugging Face, Unsloth, Claude
- Matthew Pearsons and Oussama Elachqar

## Time Log
- Start time: [Time]
- End time: [Time]
- Total hours: [Hours]
- Primary activities breakdown:
  - [Activity 1]: [Hours]
  - [Activity 2]: [Hours]
  - [...]
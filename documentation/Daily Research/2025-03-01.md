# Daily Research Journal: 2025-03-01

## Current Phase
- Phase: [1]
- Focus Area:  Identify the base model for the experiments, and commit to agent frameworks.

## Activities Completed
1. Established technical infrastructure for agent development. I will be quantizing the Deepseek R1 8b model. Hardware resources are currently limited. I aim to update the experiment with more robust models down the road, but right now we work with what we have. What we have is an M1, 16GB MacBook, with the potential to incorporate a Jetson Orin Nano and a 5700XT. 
2. Committed to AI frameworks. Initially I was going to do four philosophical frameworks, but will be moving forward with three philosophical and two governmental.
3. Set up virtual environment with required libraries. I will be incorporating Oumi for model management. Supporting open-source vendors, and ensuring this experiment can be replicated and iterated on, is central to what I want to accomplish.

## Observations
### Key Findings
- None yet. Have not begun testing the model and prompts, still building the foundation. 

## Decisions Made
- Decision: Replaced Utilitarianism with Effective Altruism.
  - Rationale: I already know the blind spots for Utilitarianism (allowing slavery because it raises master's happiness). Effective altruism is an updated version, and was mentioned in The Alignment Problem.
  - Alternatives Considered: Virtue ethics was the fourth philosophy model cut. I am still interested in adding it as I gain resources, but I have to work with limitations for now.
  - Implications: Missing how the model(s) will define what is "good." 

- Decision: Added governing body agents to the lineup. Chose Greek democracy and Roman republic.
  - Rationale: The goal is to see how a governing body would function, so I think it's important to have actual governing bodies included.
  - Alternatives Considered: Initially I thought modern day politics would be eye-opening, but the governing frameworks in America are deeply flawed right now. Let's remove recency bias.
  - Implications:  I hope for more robust decisions by incorporating specialized decision making with the value frameworks of the philosophies. I do have concern about the 3 philosophy bodies vs. 2 governing bodies. If one of the philosophies is inherently aligned with a governing body, there's the risk of systemic advantage.

## Challenges Encountered
- Resource limitations
  - Impact: Models have to be smaller, frameworks have to be excluded, more care has to be paid attention to making the models quite efficient.
  - Resolution/Plan:  Onwards and upwards. Hopefully down the road I can add an RTX 4000 series, or set a budget for an API based solution. Work with the limitations we have for now.

## Questions Raised
- What model(s) are best for the experiment?
  - Context: It's the bedrock of everything else. It will be the "personalities" of our SMEs.
  - Potential approaches to answer: Moving forward with Deepseek R1. It is currently the leader for "bang for your buck" efficiency, which has to be a consideration for now. In another version of the experiment, I'd love to try different models on the same framework with the same training/prompts and see if there's differences in their "personalities."

- What dilemmas will we put them in?
  - Context: I want a mixture of moral and governmental dilemmas to see how they approach consensus. Will one agent's dogma win out, will everyone have representation in the answer, will they reason that a particular framework isn't as relevant for a particular dilemma?
  - Potential approaches to answer: The trolley problem is a classic. I also plan for a content moderation scenario where the line has to be drawn somewhere (likely in a gray area), a resource allocation scenario for how to prioritize who/what to save, and a scenario about gentrifying an incredibly dangerous neighborhood. The last one is near and dear to me, as Cincinnati's historic Over-The-Rhine  experienced this, and it left a complicated legacy. How will it balance competing objectives, restoring a dangerous neighborhood and taking care of the people surrounded by, and contributing to, the danger?

## Next Steps
- Need to update agent framework scripts to add governing bodies, and replace utilitarianism with effective altruism
- When testing agents, look for the following behaviors:
	- **Effective Altruism Agent**: Will quantify impacts, consider long-term effects, and seek the most efficient ways to create positive outcomes.
	- **Deontological Agent**: Will consider duties, rights, and universal principles, often rejecting harmful actions even if they lead to better outcomes.
	- **Care Ethics Agent**: Will focus on relationships and context, considering how actions affect the most vulnerable and how caring connections are maintained.
	- **Democratic Process Agent**: Will prioritize inclusive decision-making processes and ensuring all stakeholders have a voice.
	- **Checks & Balances Agent**: Will focus on distributing authority, creating oversight mechanisms, and preventing concentration of power.

## Resources Used
- Oumi, Claude, Hugging Face libraries
